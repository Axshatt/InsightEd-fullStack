# InsightEd — AI-Powered Study Buddy

**InsightEd** is a friendly, student-focused chatbot and landing site built with **Next.js (App Router)**, **TypeScript**, and **Tailwind CSS**.  
It uses a server-side API route to call an OpenRouter-compatible LLM (via the `openai` npm package) and answers *only* study- and student-life-related questions (exams, study tips, productivity, academic concepts, etc.).

> Built by **Team HACKMANTHAN** — DDUGU  
> Year: 2025

---

## Features

- Clean landing page with hero, features, about, and team sections (Tailwind + Poppins font).
- Chat UI (`/chat`) with:
  - Message history and auto-scroll
  - Enter-to-send + send button
  - Bot replies generated by a server-side call to the LLM
  - System prompt guards the model to answer **only** academic/student-life queries
- Secure server-side API route that forwards queries to the LLM (so API key never lives in the browser)

---

## Quick demo

1. Start the app locally.
2. Open `http://localhost:3000` — view the landing page.
3. Go to `http://localhost:3000/chat` — talk to InsightEd.

Try asking:
- “How do I revise for my maths exam?”
- “Give me a 7-day study plan for organic chemistry.”
- If you ask unrelated things (sports, politics, entertainment), the bot will politely refuse.

---

## Requirements

- Node.js (v18+ recommended)
- npm or yarn
- A valid OpenRouter-compatible API key (we use the `openai` npm client configured with `baseURL: "https://openrouter.ai/api/v1"`)

> **Important:** Do NOT commit your API key to the repository. Use environment variables.

---

## Setup & Local Development

1. Clone the repo:
   ```bash
   git clone <your-repo-url>
   cd insighted
````

2. Install dependencies:

   ```bash
   npm install
   # or
   yarn
   ```

3. Create `.env.local` in project root and add the API key and any other env vars:

   ```env
   # .env.local (do NOT commit!)
   OPENROUTER_API_KEY=sk-or-....
   NEXT_PUBLIC_SITE_URL=http://localhost:3000
   ```

4. Start the dev server:

   ```bash
   npm run dev
   # or
   yarn dev
   ```

5. Open the app: `http://localhost:3000` and `http://localhost:3000/chat`.

---

## Project structure (important files)

```
.
├─ app/
│  ├─ layout.tsx         # global layout + font (Poppins) setup
│  ├─ page.tsx           # landing page
│  └─ chat/
│     └─ page.tsx        # Chat UI component (client)
├─ app/api/
│  └─ chat/
│     └─ route.js        # Server-side API route: calls OpenRouter model
├─ public/
│  └─ InsightEd.png
├─ tailwind.config.ts
├─ package.json
└─ README.md
```

---

## How the chat works (high-level)

1. Client sends message to the internal API route: `POST /api/chat` with `{ message }`.
2. Server route (`app/api/chat/route.js`) constructs a conversation including a **system message** that instructs the model:

   * Act as “InsightEd”
   * ONLY answer study/academic queries
   * Politely refuse unrelated requests
3. Server calls the OpenRouter-compatible API via `openai.chat.completions.create(...)`
4. Server returns model reply to the client UI
5. Client displays the reply in the chat window

This keeps the API key on the server and lets you enforce the system prompt.

---

## Example: test the API route locally (curl)

```bash
curl -X POST "http://localhost:3000/api/chat" \
  -H "Content-Type: application/json" \
  -d '{"message":"How do I prepare for a 2-hour physics exam in 2 weeks?"}'
```

Response will be JSON `{ "reply": "..." }`.

---

## Environment variables

* `OPENROUTER_API_KEY` — (required) your API key for the OpenRouter-compatible endpoint
* `NEXT_PUBLIC_SITE_URL` — (optional) used for headers/analytics if needed

> Keep these in `.env.local`. Never check them into Git.

---

## Recommended `.gitignore`

```gitignore
# Node
node_modules
npm-debug.log*
yarn-error.log

# Next.js
.next
out

# Env
.env
.env.local
.env.*.local

# Misc
.DS_Store
.vscode/
```

---

## Deployment

**Vercel** (recommended for Next.js):

* In the Vercel dashboard, set environment variables (OPENROUTER_API_KEY).
* Link your repo and deploy — Vercel will build the app.
* Make sure serverless functions have access to env vars.

Other platforms (Netlify, Render, etc.) also work — add env vars in their dashboard.

---

## Security & Privacy

* **API Key safety:** Keep your API key server-side. Do not expose it in client code or public repos.
* **User data:** If you collect or log user messages, make sure you have a privacy policy and handle PII responsibly.
* **Rate limits & cost:** Be aware of model usage costs/rate limits; add caching, throttling, or validation as needed.

---

## Extending InsightEd

Here are some easy next steps you might want to implement:

* Add user authentication and personalized dashboards.
* Persist chat history per user (DB + server).
* Build a small RAG system: index class notes / PDFs, and attach context to the model prompt.
* Add typing indicators and better streaming responses.
* Add fallbacks and model selection logic for cost/performance.

---

## Troubleshooting

* `ERR_ENV_NOT_SET` or `401` from provider:

  * Check `OPENROUTER_API_KEY` is set and correctly spelled.
* `Model not found`:

  * Confirm the model name (provider changes models over time).
* Chat replies are unrelated:

  * Adjust the server `system` message to be stricter/more explicit.

---

## Scripts (package.json)

```json
{
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint"
  }
}
```

---

## License

This project is released under the **MIT License**. See `LICENSE` for details.

---

## Contributors

* Team HACKMANTHAN — DDUGU
  (You can add GitHub handles here.)

---

## Final notes

This README gives a complete starting point for running and extending InsightEd.
If you want, I can also:

* Generate a `LICENSE` file
* Add a sample `.github/workflows/ci.yml` to run tests on push
* Add a small DB schema for storing user chats

